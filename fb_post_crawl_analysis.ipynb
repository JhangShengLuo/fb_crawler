{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import traceback\n",
    "import logging\n",
    "import seaborn as sns\n",
    "from pandas.io.json import json_normalize\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "default_stdout = sys.stdout\n",
    "default_stderr = sys.stderr\n",
    "reload(sys)\n",
    "sys.stdout = default_stdout\n",
    "sys.stderr = default_stderr\n",
    "sys.setdefaultencoding('utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_connect_output_json(url_address):\n",
    "    \"\"\"\n",
    "    \n",
    "    只是試試網頁有沒有連線成功，若成功就回傳json\n",
    "    \"\"\"\n",
    "    limit_retry_number = 20\n",
    "    for i in range(limit_retry_number):\n",
    "        try :\n",
    "            r = requests.get(url_address)\n",
    "            if r.status_code == 200:\n",
    "                r.encoding = \"utf-8\"\n",
    "                jsondata = r.json()\n",
    "                break\n",
    "            else:\n",
    "                print( \"retry \",i,\" times! 5sec between and retry only 20 times.\")\n",
    "                print( \"else sleep\")\n",
    "                time.sleep(5)\n",
    "        except (KeyboardInterrupt, SystemExit):\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            print( \"retry \",i,\" times! 5sec between and retry only 20 times.\")\n",
    "            print( \"except sleep\")\n",
    "            time.sleep(5)\n",
    "        if i == 20:\n",
    "            return {\"this url\":{\"is bad\"}}\n",
    "    return jsondata\n",
    "\n",
    "def get_page_posts_to_df(url,page_num):\n",
    "    \"\"\"\n",
    "    \n",
    "    把所有的posts抓下來，沒有判斷跟迴圈，一個分頁有25則posts只要不到一秒。\n",
    "    \"\"\"\n",
    "    jsondata = check_connect_output_json(url)['posts']\n",
    "    testdf = pd.DataFrame()\n",
    "    # 只要有分頁連結就一直往下\n",
    "    x=0\n",
    "    while 'paging' in jsondata:\n",
    "        x +=1\n",
    "        temp=json_normalize(jsondata['data']) \n",
    "        testdf=testdf.append(temp,ignore_index=True)\n",
    "        newurl = jsondata['paging']['next']\n",
    "        newr= requests.get(newurl)\n",
    "        newr.encoding=\"utf-8\"\n",
    "        jsondata = newr.json()\n",
    "        print( x,time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))\n",
    "        #若超過幾個分頁就先暫停\n",
    "        if x==page_num:\n",
    "            break\n",
    "    return testdf\n",
    "def clean_page_post(datadf):\n",
    "    \"\"\"\n",
    "    資料抓下來再處理，免得花很多時間抓結果清資料出錯又要重抓，這裡也花不到一秒。\n",
    "    \"\"\"\n",
    "    datadf=datadf[~datadf.applymap(lambda x: x == [] or x is None)]\n",
    "    datadf.dropna(axis = 1, how=\"all\",inplace=True)\n",
    "    datadf.columns = ['comments','create_time','id','link','message','name','reactions','shares','type']\n",
    "    od=['id','create_time','name','message','link','type','comments','reactions','shares']\n",
    "    datadf=datadf[od]\n",
    "    datadf.create_time =pd.to_datetime(datadf.create_time,format= \"%Y-%m-%dT%H:%M:%S+0000\")\n",
    "    datadf['create_time']=datadf.create_time + datetime.timedelta(hours=8)\n",
    "    return datadf\n",
    "\n",
    "def post_reactions(clean_post,access_token):\n",
    "    \"\"\"\n",
    "    \n",
    "    抓各個posts的reactions居然超花時間，要再花時間加上Threads，應該就會快了。\n",
    "    \"\"\"\n",
    "    id_list = clean_post.id.tolist()\n",
    "    append_temp = pd.DataFrame()\n",
    "    print( time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) , \"start reactions\")\n",
    "    for post_id in id_list:\n",
    "        react_url=reactions_number(post_id,access_token)\n",
    "        react_json=check_connect_output_json(react_url)\n",
    "        react_temp=json_normalize(react_json)\n",
    "        append_temp= append_temp.append(react_temp)\n",
    "    append_temp=append_temp[~append_temp.applymap(lambda x: x == [] or x is None)]\n",
    "    append_temp.dropna(axis = 1, how=\"all\",inplace=True)\n",
    "    append_temp.columns=['angry','haha','id','like','love','sad','wow']\n",
    "    od=['id','angry','haha','like','love','sad','wow']\n",
    "    append_temp=append_temp[od]\n",
    "    print( time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()), \"finished reactions\")\n",
    "    return append_temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reactions_number(status_id,access_token):\n",
    "    \"\"\"\n",
    "    \n",
    "    取得各個posts的reactions num，本來以為還沒有表情符號的posts的reactions會是空值，實際上只是用0顯示\n",
    "    \"\"\"\n",
    "    status_id = status_id\n",
    "    base = \"https://graph.facebook.com/v2.8\"\n",
    "    node = \"/%s\" % status_id\n",
    "    reactions = \"/?fields=\" \\\n",
    "            \"reactions.type(LIKE).limit(0).summary(total_count).as(like)\" \\\n",
    "            \",reactions.type(LOVE).limit(0).summary(total_count).as(love)\" \\\n",
    "            \",reactions.type(WOW).limit(0).summary(total_count).as(wow)\" \\\n",
    "            \",reactions.type(HAHA).limit(0).summary(total_count).as(haha)\" \\\n",
    "            \",reactions.type(SAD).limit(0).summary(total_count).as(sad)\" \\\n",
    "            \",reactions.type(ANGRY).limit(0).summary(total_count).as(angry)\"\n",
    "    parameters = \"&\"+access_token\n",
    "    url = base + node + reactions + parameters\n",
    "#     print( url)\n",
    "    return url\n",
    "def fb_pages_info(page_id,access_token):\n",
    "    # 選API版本預設2.8\n",
    "    fb_graph_api = \"https://graph.facebook.com/v2.8/\"\n",
    "    # 放粉絲頁ID\n",
    "    nodes = page_id\n",
    "    # access_token\n",
    "    access_token = access_token\n",
    "    # 所要看的欄位\n",
    "    fields =\"\"\"/?fields=posts{id,name,link,message,shares,created_time,type,comments.limit(0).summary(total_count),reactions.limit(0).summary(total_count)}\"\"\" \n",
    "    # 把url連接整理好丟出去\n",
    "    url = fb_graph_api+nodes+fields+\"&\"+access_token\n",
    "#     print( url)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2017-04-17 11:01:12\n",
      "2 2017-04-17 11:01:13\n",
      "3 2017-04-17 11:01:13\n",
      "4 2017-04-17 11:01:14\n",
      "5 2017-04-17 11:01:14\n",
      "6 2017-04-17 11:01:15\n",
      "7 2017-04-17 11:01:16\n",
      "8 2017-04-17 11:01:16\n",
      "9 2017-04-17 11:01:17\n",
      "10 2017-04-17 11:01:17\n",
      "11 2017-04-17 11:01:18\n",
      "12 2017-04-17 11:01:19\n",
      "13 2017-04-17 11:01:20\n",
      "14 2017-04-17 11:01:20\n",
      "15 2017-04-17 11:01:21\n",
      "16 2017-04-17 11:01:22\n",
      "17 2017-04-17 11:01:27\n",
      "18 2017-04-17 11:01:29\n",
      "19 2017-04-17 11:01:29\n",
      "20 2017-04-17 11:01:30\n",
      "21 2017-04-17 11:01:31\n",
      "22 2017-04-17 11:01:31\n",
      "23 2017-04-17 11:01:32\n",
      "24 2017-04-17 11:01:32\n",
      "25 2017-04-17 11:01:33\n",
      "26 2017-04-17 11:01:34\n",
      "27 2017-04-17 11:01:34\n",
      "28 2017-04-17 11:01:35\n",
      "29 2017-04-17 11:01:36\n",
      "30 2017-04-17 11:01:36\n",
      "31 2017-04-17 11:01:37\n",
      "32 2017-04-17 11:01:38\n",
      "33 2017-04-17 11:01:38\n",
      "34 2017-04-17 11:01:39\n",
      "35 2017-04-17 11:01:40\n",
      "36 2017-04-17 11:01:40\n",
      "37 2017-04-17 11:01:41\n",
      "38 2017-04-17 11:01:41\n",
      "done\n",
      "2017-04-17 11:01:41\n",
      "2017-04-17 11:01:41\n",
      "2017-04-17 11:01:41\n",
      "2017-04-17 11:06:26\n"
     ]
    }
   ],
   "source": [
    "app_id = \"\"\n",
    "app_secret = \"\"\n",
    "# 請放入自己的fb_app_token\n",
    "access_token = \"access_token=\"+app_id + \"|\" + app_secret\n",
    "\n",
    "page_id_list = ['YaoTurningTaipei','DoctorKoWJ','appledaily.tw',\"gamer.com.tw\",\"crazyck101\",\"WoTBlitzTW\"]\n",
    "# 存粹紀錄試過哪幾個粉絲團\n",
    "page_id = \"WoTBlitzTW\"\n",
    "\n",
    "url = fb_pages_info(page_id,access_token) # 所選的粉絲團的資料的url\n",
    "page_post = get_page_posts_to_df(url,50) # 把url放進去取得資料，50是要抓幾個分頁\n",
    "clean_post=clean_page_post(page_post) # 清理posts資料\n",
    "reactions=post_reactions(clean_post,access_token) # 抓posts 的reactions 然後清乾淨\n",
    "merge_reactions = pd.merge(reactions,clean_post,on=\"id\") #把reactions 跟posts合併，最後的df\n",
    "\n",
    "# merge_reactions.to_csv(page_id+'.csv',index=False)\n",
    "# merge_reactions.plot(merge_reactions.create_time,figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
